{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1) Scaling:\n",
    "\n",
    "a) MIN-MAX\n",
    "\n",
    "Write 2 scaling functions to do min-max scaling. The first, mm_params(), should take in a 2-D data array (rows are samples, columns are features) as input, and return the parameters necessary for scaling each column. The second, mm_scale(), should take in those parameters as well as a 2-D data array (rows are samples, columns are features), and return the corresponding 2-D scaled version of the data.\n",
    "\n",
    "NOTE: the reason we need to do it this way is so that later you can take in entirely new data and scale it the same way you did before you trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_params(data): #Must input a np 2D array\n",
    "        \n",
    "    min = data.min()\n",
    "    max = data.max()\n",
    "    \n",
    "    return min, max\n",
    "    \n",
    "def mm_scale(min, max, data):\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, len(data[0])):\n",
    "            \n",
    "            #Here's where the scaling happens based on the scaling definition we learned.\n",
    "            data[i][j] = ((data[i][j] - min)/(max - min))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 55 48 40 20 31 28 21 81 59]\n",
      " [16 68 24 59 23 72 29 34 19 92]\n",
      " [65 62 36 67  2 31 62 81 81 99]\n",
      " [62 13 64 20 62 75 79 39 24 10]\n",
      " [12 10 86 54 22 91 58 92 63  7]\n",
      " [93 90 96 53 78 80 26 83 28 27]\n",
      " [10 85 33 20 20 75 24 28 12  8]\n",
      " [32 37 61 20 71 29  5  8 80 91]\n",
      " [ 9 84 44 92 50 51 18 23 38 89]\n",
      " [34 40 22 80 26 48 21  6 83 52]]\n",
      "min:2 max:99\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#make a matrix of shape [2, 10] populated with random ints from 0 to 100\n",
    "matrix = np.random.randint(low=0, high=100, size=[10, 10])\n",
    "print(matrix)\n",
    "\n",
    "#print our min and max to test function 1\n",
    "min, max = mm_params(matrix)\n",
    "print(\"min:\" + str(min) + \" max:\" + str(max))\n",
    "\n",
    "#Turn our matrix into scaled values and print to test function 2\n",
    "matrix = mm_scale(min, max, matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " b) Standardization\n",
    "\n",
    "Repeat what you did in part a) for standardization based scaling instead. Call these functions st_params() and st_scale()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_params(data):\n",
    "    \n",
    "    mean = data.mean()\n",
    "    deviation = data.std()\n",
    "    \n",
    "    return mean, deviation\n",
    "\n",
    "def st_scale(mean, deviation, data):\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, len(data[0])):\n",
    "            \n",
    "            data[i][j] = ((data[i][j] - mean)/(deviation))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 88 55  9 76 98 76 90 66 80]\n",
      " [60  1  2 50 21 55 40 62 29 59]\n",
      " [58 55 99 47 56 63 21 43 36 68]\n",
      " [98 14 27 11 34 22 22 39 88 31]\n",
      " [61 62 63 66  4 77 35 32 29 74]\n",
      " [73 76 95 34 76 20 54 34 23 60]\n",
      " [87 54 90 45 73 62 89 25  5 10]\n",
      " [84 96 81 17 32 33 55 42 86 65]\n",
      " [ 7  5 65 72 67 94 93 42 80  1]\n",
      " [73 51 39 23 86 39 45 83 20 98]]\n",
      "mean:52.85 deviation:27.690566985888896\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#make a matrix of shape [2, 10] populated with random ints from 0 to 100\n",
    "matrix = np.random.randint(low=0, high=100, size=[10, 10])\n",
    "print(matrix)\n",
    "\n",
    "#print our min and max to test function 3\n",
    "mean, deviation = st_params(matrix)\n",
    "print(\"mean:\" + str(mean) + \" deviation:\" + str(deviation))\n",
    "\n",
    "#Turn our matrix into scaled values and print to test function 4\n",
    "matrix = st_scale(min, max, matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2) Confusion Matrices\n",
    "\n",
    "Write a function, co_mx(), that takes in 2 lists as inputs, one containing predicted labels and the other containing actual labels. The function should return the corresponding confusion matrix, and a list containing the correspondence between row/column index and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
       " array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def co_mx(predicted, actual):\n",
    "    \n",
    "    #Be Verbose for troubleshooting\n",
    "    #print(\"predictions:\")\n",
    "    #print(predictions)\n",
    "    #print(\"actual:\")\n",
    "    #print(actual)\n",
    "    \n",
    "    #Create a reference matrix, so that we can see what our confusion matrix looks like on the edges.\n",
    "    #The matrix Rows are the predicted values, and the columns are the actual values.\n",
    "    #Get the unique values, and put them in an array. These will go along the sides of our matrix\n",
    "    values = np.unique(actual)\n",
    "    reference = np.zeros(shape = [len(values)+1, len(values)+1])\n",
    "    reference[0][0] = 42  \n",
    "    \n",
    "    for i in range(0, len(values)):\n",
    "        reference[0][i+1] = values[i]\n",
    "        reference[i+1][0] = values[i]        \n",
    "   \n",
    "    #Be Verbose for troubleshooting:\n",
    "    #print(\"reference: (Rows = predictions, Columns = actual values)\")\n",
    "    #print(reference)\n",
    "    \n",
    "    for i in range(0, len(predicted)):\n",
    "        \n",
    "        #Be Verbose for troubleshooting:\n",
    "        #print(\"i is: \" + str(i))\n",
    "        \n",
    "        #where the predicted[i]  value is in the matrix rows. (Along the left 'column' of the Reference matrix)\n",
    "        rowIndex = np.where(reference[0] == predicted[i])\n",
    "        #Be Verbose for troubleshooting:\n",
    "        #print(\"Before transformation, rowIndex is: \" + str(rowIndex))\n",
    "        rowIndex = int(rowIndex[0])\n",
    "        \n",
    "        #where the actual[i] value is in the matrix columns (Along the top 'row' of the Reference matrix)\n",
    "        colIndex = np.where(reference[:,0] == actual[i])\n",
    "        #Be Verbose for troubleshooting\n",
    "        #print(\"Before transformation, colIndex is: \" + str(colIndex))\n",
    "        colIndex = int(colIndex[0])\n",
    "        \n",
    "        #Be Verbose for troubleshooting:\n",
    "        #print(\"rowIndex: \" + str(rowIndex))\n",
    "        #print(\"colIndex:\" + str(colIndex))\n",
    "        reference[rowIndex][colIndex] += 1\n",
    "        #print(\"reference:\")\n",
    "        #print(reference)\n",
    "        \n",
    "    #Return the array without the helping reference row and column on the top and left.\n",
    "    #Also return a list of the guesses and actual answers.\n",
    "    matrix = reference[1:, 1:]\n",
    "    predictions = reference[0][1:]\n",
    "    actual = reference[0][1:]\n",
    "    \n",
    "    return matrix, predictions, actual\n",
    "\n",
    "#Generate some random 1D arrays to toss into this function as a test. \n",
    "#We need to make sure they only fall into the same classes, so I randomly shuffle the predictions to get the actual answers.\n",
    "#We also can't have duplicates in the \"actual\" list.\n",
    "actual = np.arange(10)\n",
    "predictions = actual.copy()\n",
    "np.random.shuffle(predictions)\n",
    "\n",
    "co_mx(predictions, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3) Precision/Recall\n",
    "\n",
    "Write 2 functions, prec() and recall(), that take in 2-D confusion matrices and return the corresponding precision and recall.\n",
    "\n",
    "\n",
    "NOTE:\n",
    "Note on HW 3\n",
    "Rohan Loveland\n",
    "No unread replies. No replies.\n",
    "\n",
    "Hi all - for Precision and Recall you can assume the input confusion matrix is binary (ie 2x2).  In general, though, assume the other problems are multi-class (i.e. they should work for N classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3) Testing\n",
    "\n",
    "Generate your own data (random or made-up) to test each of your functions, and include cells in Jupyter showing your tests ofthe functions after you define them.\n",
    "\n",
    "\n",
    "Deliverables:\n",
    "\n",
    "Jupyter Notebook code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
