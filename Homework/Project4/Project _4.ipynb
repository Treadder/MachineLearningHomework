{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Polynomial Regression from Scratch\n",
    "\n",
    "In this notebook, you will write code that will:\n",
    "-  generate a dataset, \n",
    "-  model it using a polynomial regression, \n",
    "-  and find the optimal model parameters for it (writing your own optimization routine).\n",
    "\n",
    "All of the parts of this are meant to be done \"from scratch\", so do not use sklearn. (numpy's ok)  \n",
    "Note: this is a continuation of the exercise we started in class previously.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys as sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Create a dataset with 1,000 1-D X and corresponding y values, each w/ a small amount of added uniform random noise (max val = 0.1).  (So unlike example in class which had a surface and 2 features, this is like the book example with a curve with 1 feature.)\n",
    "\n",
    "-  make X go from -5 to 5 (plus noise)\n",
    "-  make $y = 5 + 7x + 2x^2 - 0.5x^3$   (plus noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 values of x_values:\n",
      "\n",
      "[-5.         -4.98998999 -4.97997998 -4.96996997 -4.95995996 -4.94994995\n",
      " -4.93993994 -4.92992993 -4.91991992 -4.90990991]\n",
      "\n",
      "added -0.04014074904760592 as noise\n",
      "added 0.03384012863295921 as noise\n",
      "added 0.04750877934612252 as noise\n",
      "added 0.013394016114333399 as noise\n",
      "added 0.07863653426609693 as noise\n",
      "\n",
      "first 10 noisy x_values:\n",
      "\n",
      "[-5.04014075 -4.95614986 -4.9324712  -4.95657595 -4.88132343 -5.00756595\n",
      " -5.01264848 -4.87451333 -5.01612164 -4.82082778]\n",
      "\n",
      "first 10 values of y_values:\n",
      "\n",
      "[84.54244732 80.30379277 79.13296298 80.32495838 76.6397965  82.8826247\n",
      " 83.1402691  76.31153078 83.31661402 73.75390232]\n",
      "\n",
      "added -0.022398825036718015 as noise\n",
      "added 0.010068683787437901 as noise\n",
      "added 0.021359856879399897 as noise\n",
      "added 0.06717950372088366 as noise\n",
      "added -0.07940396424722139 as noise\n",
      "\n",
      "first 10 noisy y_values;\n",
      "\n",
      "[84.5200485  80.31386145 79.15432284 80.39213789 76.56039253 82.86775276\n",
      " 83.19319144 76.21617264 83.3143578  73.78396463]\n",
      "\n",
      "\n",
      "matrix shape is: (2, 1000) and the [0][0] value is: -5.040140749047606\n",
      "\n",
      "now transposing matrix\n",
      "\n",
      "matrix shape is: (1000, 2) and the [0][0] value is: -5.040140749047606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note: I'm making this pretty verbose because it helps a lot with debugging.\n",
    "#Create our blank X dataset\n",
    "x_values = np.linspace(-5.0,5.0,1000)\n",
    "\n",
    "#be verbose\n",
    "print(\"first 10 values of x_values:\")\n",
    "print(\"\")\n",
    "print(x_values[0:10])\n",
    "print(\"\")\n",
    "\n",
    "#This function adds a number between -0.1 and 0.1 to the value at i in x_values. I had to pull in the smallest possible\n",
    "#number that the host machine can support in python, because random.uniform doesn't include the end number\n",
    "#and the MAX number is 0.1. That was the only way to get it in there that I could think of.\n",
    "def add_noise(numInput, verbose = False):\n",
    "    \n",
    "    lowest_add = -(0.1)\n",
    "    highest_add = (0.1 + sys.float_info.min)\n",
    "    \n",
    "    add_num = np.random.uniform(lowest_add, highest_add)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"added \" + str(add_num) + \" as noise\")\n",
    "        \n",
    "    output = numInput + add_num\n",
    "    return output\n",
    "\n",
    "#add noise to our data, and only be verbose for part of the set.\n",
    "for i in range(0, len(x_values)):\n",
    "    \n",
    "    if(i < 5):\n",
    "        x_values[i] = add_noise(x_values[i], verbose=True)#be verbose\n",
    "    else:\n",
    "        x_values[i] = add_noise(x_values[i])\n",
    "\n",
    "#be verbose\n",
    "print(\"\")\n",
    "print(\"first 10 noisy x_values:\")\n",
    "print(\"\")\n",
    "print(x_values[0:10])\n",
    "print(\"\")\n",
    "       \n",
    "#This calculates an exact y value given an x. We'll add noise in a bit.\n",
    "def calculate_y(x):\n",
    "    y = ((5) + (7*x) + (2*(x**2)) + (-0.5*(x**3)))#maybe a little overkill on the parentheses\n",
    "    return y\n",
    "    \n",
    "#Create a blank array that's the same length as x_values, and fill with zeroes for now.\n",
    "y_values = np.zeros(len(x_values))\n",
    "\n",
    "#calculate the value of y that goes in each slot of the array.\n",
    "for i in range(0, len(x_values)):\n",
    "    y_values[i] += calculate_y(x_values[i])\n",
    "    \n",
    "#be verbose\n",
    "print(\"first 10 values of y_values:\")\n",
    "print(\"\")\n",
    "print(y_values[0:10])\n",
    "print(\"\")\n",
    "\n",
    "#Add noise to our y_values. This won't affect much, as y values tend to be a LOT bigger than x values.\n",
    "for i in range(0, len(y_values)):\n",
    "    \n",
    "    if(i < 5):\n",
    "        y_values[i] = add_noise(y_values[i], verbose=True)#be verbose\n",
    "    else:\n",
    "        y_values[i] = add_noise(y_values[i])\n",
    "        \n",
    "#be verbose\n",
    "print(\"\")\n",
    "print(\"first 10 noisy y_values;\")\n",
    "print(\"\")\n",
    "print(y_values[0:10])\n",
    "print(\"\")\n",
    "        \n",
    "#make our container for everything! Also append our arrays to it.       \n",
    "matrix = []\n",
    "matrix.append(x_values)\n",
    "matrix.append(y_values)\n",
    "\n",
    "#Be verbose\n",
    "print(\"\")\n",
    "print(\"matrix shape is: \" + str(np.shape(matrix)) + \" and the [0][0] value is: \" + str(matrix[0][0]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"now transposing matrix\")\n",
    "print(\"\")\n",
    "\n",
    "#put it in column-standard configuration, and print out an index that should stay the same to make sure it worked\n",
    "matrix = np.transpose(matrix)\n",
    "\n",
    "print(\"matrix shape is: \" + str(np.shape(matrix)) + \" and the [0][0] value is: \" + str(matrix[0][0]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment X\n",
    "Write a function that adds new columns to the dataset of powers of X, up to and including $X^5$ (and don't forget the ones for the $\\theta_0$ term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 values of x_values:\n",
      "[-4.95929687 -5.0471254  -4.94798953 -5.02139682 -5.02132325]\n",
      "\n",
      "first 5 values of x_to_zero\n",
      "[-4.95929687 -5.0471254  -4.94798953 -5.02139682 -5.02132325]\n"
     ]
    }
   ],
   "source": [
    "#my interpretation is that I am adding columns of x in which x is raised to the n'th power. These columns will\n",
    "#be placeholders that will get multiplied by our fifth-degree polynomial's weights later for testing. I don't see this \n",
    "#actually happening in real use-cases, because it seems a bit expensive for large data sets.\n",
    "\n",
    "#Grab our x_values array for easy refrence and use here.\n",
    "x_values = matrix[:,0]\n",
    "\n",
    "#raises all values in an array to the specified power, and returns the new array\n",
    "def raise_array_values_to_power(array, power):\n",
    "    return_array = np.zeros(len(array))#make a new array to put everything in to stay safe\n",
    "    for i in range(0, len(array)):\n",
    "        return_array[i] += array[i]**power\n",
    "    return array\n",
    "\n",
    "#raises all x values to n. Be careful not to corrupt refrence array!\n",
    "x_to_zero = raise_array_values_to_power(x_values, 0)\n",
    "x_to_one = raise_array_values_to_power(x_values, 1)\n",
    "x_to_two = raise_array_values_to_power(x_values, 2)\n",
    "x_to_three = raise_array_values_to_power(x_values, 3)\n",
    "x_to_four = raise_array_values_to_power(x_values, 4)\n",
    "x_to_five = raise_array_values_to_power(x_values, 5)\n",
    "\n",
    "#be verbose\n",
    "print(\"first 5 values of x_values:\")\n",
    "print(x_values[0:5])\n",
    "print(\"\")\n",
    "print(\"first 5 values of x_to_zero\")\n",
    "print(x_to_zero[0:5])#should all be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Polynomial Regression model to the training data\n",
    "Assume that we have a polynomial regression model\n",
    "\\begin{equation*}\n",
    "y(X;\\theta) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 +\\theta_5 x^5 \n",
    "\\end{equation*}\n",
    "\n",
    "Assume that we're using a mean squared error function.\n",
    "\n",
    "-  Find the optimal value of theta (ie $\\theta_0$ through $\\theta_5$). Note: Refer to Ch. 4, Eqn's 4.6 and 4.7.\n",
    "\n",
    "-  Try this for a variety of different values of alpha.  Note how long it takes for the optimization to converge (or if it doesn't).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Final Model\n",
    "Make a plot showing the (X,y) data points of the training set, and superimpose the line for the model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Model Degrees\n",
    "Try the model for different degrees of n, specifically n = (2, 5, 10).  Plot the resulting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
